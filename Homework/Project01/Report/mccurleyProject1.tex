\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{lettrine}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{subfig}




\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}



\graphicspath{{"C:/Users/Conma/Documents/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"} {"/media/edrive/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"}}

\begin{document}

\title{Project 1: Manifold Learning for Fashion-MNIST Classification}
\author{\IEEEauthorblockN{Connor McCurley}
\IEEEauthorblockA{\textit{Deep Learning, Fall 2019} \\
\textit{University of Florida}\\
Gainesville, FL, USA 32611 \\
Email: cmccurley@ufl.edu}

}

\maketitle


\begin{abstract}
	
\end{abstract} 

\begin{IEEEkeywords}
Neural Network, Dimensionality Reduction, Manifold Learning, Multi-Layer Perceptron, Fashion MNIST
\end{IEEEkeywords}


%===============================================================================================================================================================================================
\section{Introduction} 

\lettrine{A}{utonomous} image classification is a challenging problem which offers potential for significant advancement in the areas of biometrics, biology, medical diagnosis, security, and more \textbf{CITE}.  This paper focuses on the use of dimensionality reduction/ manifold learning in conjunction with multi-layer perceptron artificial neural networks to automatically classify clothing items from the well-known Fashion MNIST dataset \textbf{CITE}.  \\
\indent A wide variety of approaches have been taken in attempt to solve detection and classification problems in imagery.

%===============================================================================================================================================================================================

\section{Methodology} \label{Methodology}

	\subsection{Data Analysis}
	
	\subsection{Dimensionality Reduction}
	
	\subsubsection*{Supervised}
	\subsubsection*{Linear}
	\subsubsection*{Nonlinear}
	\subsubsection*{Global}
	\subsubsection*{Local}
	
	\subsection{Network Architecture}
	
	
	
%	\begin{center}
%		\begin{figure*}[h]
%			\centering
%			\includegraphics[width=\textwidth]{"Raw"}
%			\caption{Raw audio signals. Top: Training segments of 10 unique manatee categories.  Middle: Raw training data for background noise.  Bottom: Raw test signal colored by hand-created labels.  Red portions signify segments from 16 unique manatee observations, while blue represents background noise.}
%			\label{fig:Raw}
%		\end{figure*}
%	\end{center}
	





	


\subsection{Experiments} \label{Experiments}



%===============================================================================================================================================================================================
\section{Results} \label{Results}





%\begin{table}[h!]
%	\caption{AUC for Various Signature Generation Methods}
%	\label{tab:AUC}
%	\normalsize
%	\begin{center}
%		\begin{tabularx}{0.5\textwidth}{ |X|X| } 
%			\hline
%			\textbf{Signature Creation}  & \textbf{AUC} \\
%			\hline
%			Average & 0.8406 \\
%			\hline
%			\textbf{Median} & \textbf{0.8414} \\
%			\hline
%			Combined Manatee Bag & 0.4472 \\
%			\hline
%			Individual Manatee Bags & 0.7379 \\
%			\hline
%			Six Bags per Manatee & 0.8133 \\
%			\hline
%			10 Bags per Manatee & 0.8085 \\
%			\hline
%		\end{tabularx}
%	\end{center}
%\end{table} 


%===============================================================================================================================================================================================

\section{Discussion} \label{Discussion}
In this sections, observations are made on results and insight is given to potential influences.

\subsection{Results}



\subsection{Potential Improvements}



%===============================================================================================================================================================================================
\section{Conclusions} \label{Conclusions}
A
%===============================================================================================================================================================================================

\section*{Honor Statement}
\noindent
* I confirm that this assignment is my own work, it is not copied from any other person's work (published or unpublished), and has not been previously submitted for assessment either at University of Florida or elsewhere.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.20\textwidth]{"Signature"}
\end{figure}

%\begin{thebibliography}{00}
%%Adaptive Filters================================================
%\bibitem{Liu}Liu, Weifeng., Principe, Jose C., Haykin, Simon. "Chapter 1 - Background and Preview", "Chapter 2 - Kernel Least-Mean-Square Algorithm", in \textit{Kernel Adaptive Filtering: A Comprehensive Introduction}, New Jersey: John Wiley \& Sons, Inc., Publication, 2010, pp. 1-26, 27-68.
%
%\bibitem{NonStationarity}Fancourt, Craig L., Principe, Jose C. "Exploiting Multi-Modality for Segmentation and Modeling of Non-Stationary Time Series" in \textit{Nonlinear dynamical systems : feedforward neural network perspectives.} New York : John Wiley, c2001., 2001. (Adaptive and learning systems for signal processing, communications, and control). ISBN: 0471349119.
%
%%MFCC
%\bibitem{WienerFiltMFCC}Chauhan, P. M., Desai, N.P. "Mel Frequency Cepstral Coefficients (MFCC) Based Speaker Identification in Noisy Environment Using Wiener Filter" in \textit{Proceeding of the IEEE International Conference on Green Computing, Communication and Electrical Engineering}. 2014.
%
%\bibitem{ChoosingMFCC}Grama, L, Rusu, C. "Choosing an accurate number of mel frequency cepstral coefficients for audio classification purpose" in \textit{International Symposium on Image and Signal Processing and Analysis}. 2017. pp. 225--230.
%
%\bibitem{MFCCSpeakerRecognitioin}Tiwari, V. "MFCC and its applications in speaker recognition" in \textit{International Journal on Emerging Technologies}. 2010. pp. 19-22
%
%\bibitem{MFCCVectorQuant}Nijhawan, G., Soni, M. K. "Speaker Recognition Using MFCC and Vector Quantisation" in \textit{International Journal on Recent Trends in Engineering and Technology}. 2014. vol. 11. pp. 211-218.
%
%\bibitem{RealTimeMFCC}Bharti, R., Bansal, P. "Real Time Speaker Recognition System using MFCC and Vector Quantization Technique" in \textit{International Journal of Computer Applications}. 2015. vol. 117. pp. 25-31.
%
%\bibitem{MFCCSlides}Prahallad, K. "Topic:Spectrogram, Cepstrum and Mel-Frequency Analysis" in \textit{Speech Technology: A Practical Introduction}.
%
%%MI====================================================================
%\bibitem{MISurvey}Carbonneau, M., Cheplygina, V., Granger, E., Gagnon, G. "Multiple Instance Learning: A Survey of Problem Characteristics and Applications" 2016.  Available: \url{http://arxiv.org/abs/1612.03365}
%
%\bibitem{miACE}Jiao, C., Zare, A., Mcgarvey, R. "Multiple Instance Hybrid Estimator for Hyperspectral Target Characterization and Sub-pixel Target Detection". Under Review. 04/19/2019. Available: \url{https://arxiv.org/pdf/1710.11599.pdf}
%
%\bibitem{WeaklySupervisedAudio}Kumar, A., Raj, B. "Weakly Supervised Scalable Audio Content Analysis" 2016. Available: \url{https://arxiv.org/pdf/1606.03664.pdf}
%
%\bibitem{MISlides}Carbonneau, M. "Introduction to Multiple Instance Learning". 10/19/2016. Online. Available: \url{https://www.etsmtl.ca/Unites-de.../Introduction-to-Multiple-Instance-Learning.pdf}
%
%%SVM===================================================================
%\bibitem{miSVM}Andrews, S. Tsochantaridis, I., Hofmann, T. "Support Vector Machines for Multiple-Instance Learning". Online. Available: \url{https://pdfs.semanticscholar.org/3447/fe054f6af70403cfc39b4d21076337a71128.pdf} Accessed: April, 2018.
%
%\bibitem{Birds}Fagerlund, S.  "Bird species recognition using support vector machines" in \textit{Eurasip Journal on Advances in Signal Processing}. 2007. 
%
%\bibitem{AudioClassificationMachineLearning}Rong, F. "Audio classification method based on machine learning" in \textit{Intelligent Transportation, Big Data \& Smart City}. 2016.
%
%\bibitem{WaveletsSupportVector}Lin,C.,Chen, S., Truong, T., Chang, Y. "Audio Classification and Categorization Based on Wavelets and Support Vector Machine" in \textit{IEEE Transactions on Speech and Audio Processing}. 2005. vol. 5. pp. 644-651.
%
%\bibitem{ContentBased}Guo, G., Li, S.Z. "Content-Based Audio Classification and Retrieval by Support Vector Machines" in \textit{IEEE Transactions on Neural Networks}. 2003. vol. 14 no. 1, pp. 209-215.
%
%\bibitem{SVMSlides}Andrews, S., Tsochantaridis, I. Hofmann, T. "Support Vector Machines for Multiple-Instance Learning". Online. Available: \url{http://www.robots.ox.ac.uk/~vgg/rg/slides/07_06_11_Chai.pdf}. Accessed: April, 2018.
%
%%HMM===================================================================
%\bibitem{HMMBird}Jancovic, P., Kokuer, M. "Automatic Detection of Bird Species from Audio Field Recordings using HMM-based Modeling of Frequency Tracks" in \textit{25th European Signal Processing Conference}. 2017.
%
%\bibitem{HMMSpeechSegmentation}Brognaux, S., Drugman, T. "HMM-Based Speech Segmentation: Improvements of Fully Automatic Approaches" in \textit{IEEE/ ACM Transactions on Audio, Speech, and Language Processing}. 2016. vol. 24, no. 1, pp. 5-15.
%
%\bibitem{InstrumentRecognition}Zhu, B., Gan, J., Cai, J., Wang, Y., Wang, H. "Adaptive onset detection based on instrument recognition" in \textit{ICSP2014, Proceedings of}. 2014.
%
%
%%NeuralNet=============================================================
%\bibitem{SpeakerRecognitionANN}Chauhan, N., Chandra, M. "Speaker Recognition and Verification Using Artificial Neural Network" in \textit{IEEE WiSPNET Conference}. 2017,
%
%\bibitem{FilterBankDeepNN}Fredes, J., Novoa, J., King, S., Stern, R.M., Yoma, N.B. "Locally Normalized Filter Banks Applied to Deep Neural-Network-Based Robust Speech Recognition" in \textit{IEEE Signal Processing Letters}. 2017. vol. 24, no. 4, pp. 377-381.
%
%\bibitem{DNNLanguage}Richardson, F., Reynolds, D., Dehak, N. "Deep Neural Network Approaches to Speaker and Language Recognition" in \textit{IEEE Signal Processing Letters}. 2015. vol. 22, no. 10, pp. 1671 - 1675.
%
%%Anomaly Detection=====================================================
%\bibitem{LinearPrediction}Ho, K.C., Gader, P.D. "A Linear Prediction Land Mine Detection Algorithm for Hand Held Ground Penetrating Radar" in \textit{IEEE Transactions on Geoscience and Remote Sensing}. 2002. vol. 40, no. 6, pp. 1374-1384.
%
%
%\end{thebibliography}


\end{document}
