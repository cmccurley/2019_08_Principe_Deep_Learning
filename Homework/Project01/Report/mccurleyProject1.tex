\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage[round]{natbib}
\usepackage[noadjust]{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{lettrine}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{subfig}




\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}



\graphicspath{{"C:/Users/Conma/Documents/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"} {"/media/edrive/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"}}

\begin{document}

\title{Project 1: Manifold Learning for Fashion-MNIST Classification}
\author{\IEEEauthorblockN{Connor McCurley}
\IEEEauthorblockA{\textit{Deep Learning, Fall 2019} \\
\textit{University of Florida}\\
Gainesville, FL, USA 32611 \\
Email: cmccurley@ufl.edu}

}

\maketitle


\begin{abstract}
	This paper investigates the use of manifold learning as a preprocessing procedure for object classification in grayscale imagery.  Four manifold learning methods exhibited in the literature were compared in terms of their contributions to enforcing class discriminability.  Two individual multi-layer perceptron classifier architectures were trained for each dimensionality reduction technique and compared to a baseline model. Experiments were conducted on the Fashion-MNIST dataset and results were presented in the form of confusion matrices.  The optimal detector demonstrated performance of ... this was an increase of ... over the baseline.  More experimentation could be performed to optimize the parameters of each manifold learning method and to potentially discover the true intrinsic dimensionality of the Fashion-MNIST dataset.
\end{abstract} 

\begin{IEEEkeywords}
Neural Network, Dimensionality Reduction, Manifold Learning, Multi-Layer Perceptron, Fashion MNIST
\end{IEEEkeywords}


%===============================================================================================================================================================================================
\section{Introduction} 

\lettrine{A}{utonomous} image classification is a challenging problem which offers potential for significant advancement in the areas of biometrics, biology, medical diagnosis, security, and more \cite{Prasad2015Review,Lu2007Review}.  This paper focuses on the use of dimensionality reduction/ manifold learning in conjunction with multi-layer perceptron artificial neural networks to automatically classify clothing items from the well-known Fashion MNIST dataset \cite{Xiao2017FashionMNIST}.  \\
\indent A wide variety of approaches have been taken in attempt to solve detection and classification problems in imagery.  \cite{Mensink2013KNN} used dissimilarity-based classifiers along with metric learning to dually drive samples toward their respective class representatives while also enforcing separation between classes.  \cite{Sanchez2011svm,Lin2011svm} utilized vector embeddings with linear support vector machines to discriminate between low-dimensional image representations.  The work in \cite{Shao2019DictionaryLearning} found sparse weighted combinations of dictionary atoms to accurately reconstruct images where specific bases equated to the various  classes.  The authors of \cite{Timofte2013NaiveBayes} utilized statistical properties to match samples to generating distributions.  The work in \cite{Swaroop2016TemplateMatching} employed traditional template matching to locate objects or compositions in imagery.  The review in \cite{Driss2017MLPandCNN} demonstrated that expansive uses of artificial neural networks in image classification.  This, of course, is just a small sample of image classification techniques.  The reviews in \cite{Prasad2015Review,Lu2007Review} elaborate extensively on the myriad of methods.  A commonality among all of the discussed methods is that they suffer from high-dimensionality.  Because of this fact, this work explores the use of dimensionality reduction as a preprocessing procedure for classification with fully-connect multi-layer perceptrons. \\
\indent The remainder of this paper is organized as follows.  Section \ref{Methodology} describes the methodology used to perform dimensionality reduction and classification with multilayer perceptrons.  Classification results are presented in Section \ref*{Results}.  Practical insights to results are given in Section \ref{Discussion}.  Finally, Section \ref{Conclusions} reveals concluding remarks and discusses future lines of research.


%===============================================================================================================================================================================================

\section{Methodology} \label{Methodology}
	This section describes the methodology used throughout this work.  Analysis of the data is performed, dimensionality reduction techniques are described, various network architectures under analysis are elaborated on and the experimental procedure is outlined.

	\subsection{Data Analysis}
	The data was first plotted as shown in Figure \textbf{REF} to gain an understanding of the format.  Each sample in the Fashion-MNIST dataset is a 28x28, gray-scale image of a clothing item belonging to one of ten classes \cite{Xiao2017FashionMNIST}. This translates to 784 length feature vectors with values ranging between 0-255. There were exactly 60000 training images included in the  training dataset and 10000 which were held-out for test.  The 60000 samples were later sub-divided in the experimentation for cross-validation. Histograms of one-versus-all Euclidean distances to each of the classes are shown in Figure \textbf{REF} to gain a sense of class separability using the raw images, solely.  Given that the classifier would be a multi-layer perceptron artificial neural network, it was determined that dimensionality reduction should be utilized to combat the Curse of Dimensionality, while potentially improving class discriminability.
	
	\subsection{Dimensionality Reduction}
	Manifold learning, feature extraction, dimensionality reduction (DR) and representation learning are all synonymous for methods that learn representations of data that make it easier to extract useful information when building classifiers or other predictors \cite{Bengio2014RepLearningReview}. Traditionally, DR transforms high-dimensional data into meaningful representations of reduced dimensionality.  There is an expansive taxonomy of DR techniques, ranging from linear to non-linear, globally preserving to locally preserving, variance retaining to discriminability enforcing, among others \cite{VanDerMaaten2009DRReview}.  A small taxonomy of DR techniques is shown in Figure \textbf{REF}.   Dimensionality reduction has been used in a wide variety  of applications, including: speech recognition and signal processing, object recognition, computer vision, multi-task learning and domain adaptation \cite{Bengio2014RepLearningReview}, multi-modal sensor alignment \cite{zhang2010multisourceremotingsensingfusion,Davenport2010JointManifoldsDataFusion}, pose estimation \cite{Navaratnam2007JointManifoldSemiSupRegression}, land-use classification \cite{Hong2019LearnableManifoldAlignment}, medical diagnosis, meteorology, environmental monitoring, economic forecasting and more \cite{Zitova2003SurveyImageRegistrationMethods}.  Nine methods were originally considered for this work, constituting a mix of linear and non-linear techniques.  These methods include: Principal Component Analysis (PCA) \cite{Tipping1999PPCA,Murphy2012Textbook}, Fisher's Linear Discriminant (FLDA) \cite{Murphy2012Textbook,Sugiyama2006FDASupDimRed}, t-Distributed Stochastic Neighbor Embedding (t-SNE) \cite{vanDerMaaten2008tSNE}, Uniform Manifold Approximation and Projection (UMAP) \cite{McInnes2018UMAP}, Auto-encoders \cite{Haykin2009NeuralNetworks,Goodfellow2016DeepLearning}, Self-Organizing Feature Maps (SOM) \cite{Haykin2009NeuralNetworks,Kohonen1990SOM,Fritzke1995GrowingNeuralGas}, Isometric Feature  Mapping (Isomap) \cite{Tenenbaum2000Isomap,Thorstensen2009ManifoldThesis,VanDerMaaten2009DRReview}, Locally Linear Embedding (LLE) \cite{Roweis2000LLE,Saul2001LLEIntro}, and Laplacian Eigenmaps \cite{Belkin2003LaplacianEigenmaps,VanDerMaaten2009DRReview}.  While each of these methods have shown efficacy in various arenas, only four methods were selected for further review in this work. Fisher's Linear Discriminant, t-SNE, and UMAP each consider label information to ensure within-class compactness and/or between-class separation.  Autoencoder networks were also used to provide an ``unsupervised" approach.  They are only referred to as unsupervised in this work because they do not consider class information when defining latent feature representations. These techniques are further described in the following:
	
	\subsubsection*{Fisher's Linear Discriminant Analysis (FLDA)}  Compared to PCA, whose ultimate goal is to maximize the variance in each orthogonal dimension of the latent space, the objective of FLDA is to maximize discriminability through a supervised linear projection of data.  This is realized by solving a generalized eigenvalue problem, thus minimizing intra-class variability and maximizing inter-class variability \cite{Murphy2012Textbook,Sugiyama2006FDASupDimRed}.  Given that FLDA is a linear dimensionality reduction technique, it is unreasonable to assume that it will be able to approximate highly nonlinear manifolds well.   However, linear methods are applicable to out-of-sample datapoints, meaning the transformation can easily be applied to new data during test.
	
	\subsubsection*{t-Distributed Stochastic Neighbor Embedding (t-SNE)} t-SNE is currently a state-of-the-art method for dimensionality reduction and data visualization. Stochastic Neighbor Embedding (SNE) uses radial basis functions  to convert high-dimensional Euclidean distances between datapoints into conditional probabilities representing similarities.  SNE then uses a cost based on KL divergence to match pairwise distributions between data representations in the high and low-dimensional spaces.  Since KL divergence is asymmetric, different types of errors are not weighted equally in the cost.  For example, there is a larger penalty for using very dissimilar points to represent nearby datapoints.  t-SNE is a modification of SNE in which the RBF kernels are replaced by the heavy-tailed student-t distribution \cite{vanDerMaaten2008tSNE} to alleviate crowding and optimization problems present in SNE.  By placing emphasis on the pairwise distances of datapoints, t-SNE captures both local manifold information and global structure such as the presence of clusters at several scales. However, t-SNE only guarantees that within-cluster distances are meaningful, so clustering is not necessarily optimal.
	\subsubsection*{Uniform Manifold Approximation and Projection (UMAP)} UMAP is another SOA manifold learning algorithm which, at first sight, is very similar to t-SNE.  While outwardly equivalent to t-SNE, UMAP addresses some of the pitfalls of t-SNE.  UMAP substitutes a binary cross-entropy cost function for KL-divergence which makes it capable of capturing global structure, and by ignoring probability normalization, the time for high-dimensional graph computation is drastically reduced \cite{McInnes2018UMAP}.
	\subsubsection*{Autoencoder} An autoencoder is a specific taxonomy of artificial neural networks whose output has the same dimensionality as the input and whose desired is actually the input sample \cite{Haykin2009NeuralNetworks,Goodfellow2016DeepLearning}. Typically, autoencoders enforce dimensionality reduction operations up to their middle layers.  This portion of the network is known as the `encoder', since it projects data into a lower dimensional space.  The second half of the network projects the data back into its original dimensionality in attempt to reconstruct the original sample.  This section of the network is known as the `decoder'. (See Figure \textbf{REF}.)  In practice, samples can be passed through the encoder to perform dimensionality reduction. 
	 
	\subsection{Network Architecture}
	Three individual multi-layer perceptron architectures were implemented in this work.  Each of the architectures maintained similar structure with the exception of the input layer, which was varied to test the effects of dimensionality reduction.  After the input, the networks consisted of layers (input-256-128-100-10) Figure \textbf{REF} shows a block diagram of the implemented networks.   The input sizes were varied from the original dimensionality (784), to reduced dimensionality of 400, 100 and 9.  ReLU activation functions were used in all layers of the network, excluding the output.  Cross-entropy was the utilized cost function and the Adamax implementation in Pytorch was used to update the weights.
	
	
%	\begin{center}
%		\begin{figure*}[h]
%			\centering
%			\includegraphics[width=\textwidth]{"Raw"}
%			\caption{Raw audio signals. Top: Training segments of 10 unique manatee categories.  Middle: Raw training data for background noise.  Bottom: Raw test signal colored by hand-created labels.  Red portions signify segments from 16 unique manatee observations, while blue represents background noise.}
%			\label{fig:Raw}
%		\end{figure*}
%	\end{center}
	





	


\subsection{Experiments} \label{Experiments}



%===============================================================================================================================================================================================
\section{Results} \label{Results}





%\begin{table}[h!]
%	\caption{AUC for Various Signature Generation Methods}
%	\label{tab:AUC}
%	\normalsize
%	\begin{center}
%		\begin{tabularx}{0.5\textwidth}{ |X|X| } 
%			\hline
%			\textbf{Signature Creation}  & \textbf{AUC} \\
%			\hline
%			Average & 0.8406 \\
%			\hline
%			\textbf{Median} & \textbf{0.8414} \\
%			\hline
%			Combined Manatee Bag & 0.4472 \\
%			\hline
%			Individual Manatee Bags & 0.7379 \\
%			\hline
%			Six Bags per Manatee & 0.8133 \\
%			\hline
%			10 Bags per Manatee & 0.8085 \\
%			\hline
%		\end{tabularx}
%	\end{center}
%\end{table} 


%===============================================================================================================================================================================================

\section{Discussion} \label{Discussion}
In this sections, observations are made on results and insight is given to potential influences.

\subsection{Results}

\subsection{Effects of Manifold Learning/ Dimensionality Reduction}


\subsection{Potential Improvements}



%===============================================================================================================================================================================================
\section{Conclusions} \label{Conclusions}
A
%===============================================================================================================================================================================================

\section*{Honor Statement}
\noindent
* I confirm that this assignment is my own work, it is not copied from any other person's work (published or unpublished), and has not been previously submitted for assessment either at University of Florida or elsewhere.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.20\textwidth]{"Signature"}
\end{figure}

\bibliography{Project1}
\bibliographystyle{IEEEtran}
%\bibliographystyle{plainnat}

\end{document}
