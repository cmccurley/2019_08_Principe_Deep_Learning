\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage[round]{natbib}
\usepackage[noadjust]{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{lettrine}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{subfig}




\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}



\graphicspath{{"C:/Users/Conma/Documents/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"} {"/media/edrive/2019_08_Principe_Deep_Learning/Homework/Project01/Report/Images/"}}

\begin{document}

\title{Project 1: Manifold Learning for Fashion-MNIST Classification}
\author{\IEEEauthorblockN{Connor McCurley}
\IEEEauthorblockA{\textit{Deep Learning, Fall 2019} \\
\textit{University of Florida}\\
Gainesville, FL, USA 32611 \\
Email: cmccurley@ufl.edu}

}

\maketitle


\begin{abstract}
	
\end{abstract} 

\begin{IEEEkeywords}
Neural Network, Dimensionality Reduction, Manifold Learning, Multi-Layer Perceptron, Fashion MNIST
\end{IEEEkeywords}


%===============================================================================================================================================================================================
\section{Introduction} 

\lettrine{A}{utonomous} image classification is a challenging problem which offers potential for significant advancement in the areas of biometrics, biology, medical diagnosis, security, and more \textbf{CITE}.  This paper focuses on the use of dimensionality reduction/ manifold learning in conjunction with multi-layer perceptron artificial neural networks to automatically classify clothing items from the well-known Fashion MNIST dataset \textbf{CITE}.  \\
\indent A wide variety of approaches have been taken in attempt to solve detection and classification problems in imagery.

%===============================================================================================================================================================================================

\section{Methodology} \label{Methodology}

	\subsection{Data Analysis}
	The data was first plotted as shown in Figure \textbf{REF} to gain an understanding of the format.  Each sample in the Fashion-MNIST dataset is a 28x28, gray-scale image of a clothing item belonging to one of ten classes. This translates to 784 length feature vectors with values ranging between 0-255. There were exactly 60000 training images included in the  training dataset and 10000 which were held-out for test.  The 60000 samples were later sub-divided in the experimentation for cross-validation. Histograms of one-versus-all Euclidean distances to each of the classes are shown in Figure \textbf{REF} to gain a sense of class separability using the raw images, solely.  Given that the classifier would be a multi-layer perceptron artificial neural network, it was determined that dimensionality reduction should be utilized to combat the Curse of Dimensionality, while potentially improving class discriminability.
	
	\subsection{Dimensionality Reduction}
	Manifold learning, feature extraction, dimensionality reduction (DR) and representation learning are all synonymous for methods that learn representations of data that make it easier to extract useful information when building classifiers or other predictors \cite{Bengio2014RepLearningReview}. Traditionally, DR transforms high-dimensional data into meaningful representations of reduced dimensionality.  There is an expansive taxonomy of DR techniques, ranging from linear to non-linear, globally preserving to locally preserving, variance retaining to discriminability enforcing, among others \cite{VanDerMaaten2009DRReview}.  A small taxonomy of DR techniques is shown in Figure \textbf{REF}.   Dimensionality reduction has been used in a wide variety  of applications, including: speech recognition and signal processing, object recognition, computer vision, multi-task learning and domain adaptation, multi-modal sensor alignment, natural language processing, pose estimation, land-use classification, medical diagnosis, meteorology, environmental monitoring, economic forecasting and more.
	
	\subsubsection*{Supervised}
	\subsubsection*{Linear}
	\subsubsection*{Nonlinear}
	\subsubsection*{Global}
	\subsubsection*{Local}
	
	\subsection{Network Architecture}
	
	
	
%	\begin{center}
%		\begin{figure*}[h]
%			\centering
%			\includegraphics[width=\textwidth]{"Raw"}
%			\caption{Raw audio signals. Top: Training segments of 10 unique manatee categories.  Middle: Raw training data for background noise.  Bottom: Raw test signal colored by hand-created labels.  Red portions signify segments from 16 unique manatee observations, while blue represents background noise.}
%			\label{fig:Raw}
%		\end{figure*}
%	\end{center}
	





	


\subsection{Experiments} \label{Experiments}



%===============================================================================================================================================================================================
\section{Results} \label{Results}





%\begin{table}[h!]
%	\caption{AUC for Various Signature Generation Methods}
%	\label{tab:AUC}
%	\normalsize
%	\begin{center}
%		\begin{tabularx}{0.5\textwidth}{ |X|X| } 
%			\hline
%			\textbf{Signature Creation}  & \textbf{AUC} \\
%			\hline
%			Average & 0.8406 \\
%			\hline
%			\textbf{Median} & \textbf{0.8414} \\
%			\hline
%			Combined Manatee Bag & 0.4472 \\
%			\hline
%			Individual Manatee Bags & 0.7379 \\
%			\hline
%			Six Bags per Manatee & 0.8133 \\
%			\hline
%			10 Bags per Manatee & 0.8085 \\
%			\hline
%		\end{tabularx}
%	\end{center}
%\end{table} 


%===============================================================================================================================================================================================

\section{Discussion} \label{Discussion}
In this sections, observations are made on results and insight is given to potential influences.

\subsection{Results}



\subsection{Potential Improvements}



%===============================================================================================================================================================================================
\section{Conclusions} \label{Conclusions}
A
%===============================================================================================================================================================================================

\section*{Honor Statement}
\noindent
* I confirm that this assignment is my own work, it is not copied from any other person's work (published or unpublished), and has not been previously submitted for assessment either at University of Florida or elsewhere.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.20\textwidth]{"Signature"}
\end{figure}


\newpage

\bibliography{Project1}
\bibliographystyle{IEEEtran}
%\bibliographystyle{plainnat}

\end{document}
