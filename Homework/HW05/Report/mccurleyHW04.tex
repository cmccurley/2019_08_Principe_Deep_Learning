\documentclass{article}[12 pt]
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{appendix}
\usepackage{array}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{caption}
\usepackage{url}
\usepackage{float}
\usepackage{pdfpages}
\usepackage{shortvrb}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{commath}
\usepackage{tabularx}
\usepackage{bm}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\graphicspath{{"E:/University of Florida/Classes/2019_08_Principe_Deep_Learning/Homework/HW04/Report/Images/"}{"C:/Users/Conma/Documents/2019_08_Principe_Deep_Learning/Homework/HW04/Report/Images/"}{"/media/cmccurley/0000-0001/University of Florida/Classes/2019_08_Principe_Deep_Learning/Homework/HW04/Report/Images/"}}
\geometry{margin=1 in}

\newcommand{\smallvskip}{\vspace{5 pt}}
\newcommand{\medvskip}{\vspace{30 pt}}
\newcommand{\bigvskip}{\vspace{100 pt}}
\newcommand{\tR}{\mathtt{R}}




\begin{document}
	
\begin{center}
	\textbf{\Large Connor McCurley} \\
	EEE 6814 \qquad \textbf{\large Homework 4} \qquad Fall 2019 
\end{center}


This assignment tasked us with applying multi-resolution PCA as a pre-processing procedure for Fashion-MNIST classification. To be honest, I never fully understood the implementation of PCA-M demonstrated in the paper (the steps were really not clear). So I implemented my own version of multi-resolution PCA (which may or may not be valid).   To do this, I took the full-resolution images (28x28) and generated (14x14), (7x7) and (3x3) lower-resolution versions.  For each image resolution, I estimated the means and covariances of the training set.  The full set of eigenvectors of the covariance matrix are commonly referred to as the  ``eigenface space" in the literature.  Projecting individual images onto the full space provides weights which represent the amount each eigenvector contributes toward reconstructing the image.   To generate features for an image, the following was employed:

\begin{enumerate}
	\item Vectorize the (14x14) image
	\item Take the first three eigenvectors multiplied by the images' reconstruction weight
	\item Concatenate those four images
	\item Repeat for the (7x7) and (3x3) images
	\item Concatenate all features to make a 1016 length feature vector for the image 
\end{enumerate}

\noindent
This process is exhibited in Figures \ref{fig:sub1},\ref{fig:sub2}, and \ref{fig:sub3}.  The images on the left show the full (28x28) sample. In the right images, the top row (from left to right) corresponds to the full (14x14) resolution image, the reconstruction contribution of the first principal vector, followed by the second and third.  The middle row corresponds to the same for the (7x7) image and the bottom row demonstrates the (3x3) resolution image.  Each of the images on the right are vectorized and concatenated to form 1016 length feature vectors.
\vspace{-0.3cm}

\begin{figure}[h]
	\centering
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_0_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_0_multi_res"}}\\
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_10000_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_10000_multi_res"}}
	\caption{Full resolution images (left) and corresponding multi-resolution PCA features (right) for two training examples.}
	\label{fig:sub1}
\end{figure}

\begin{figure}[!h]
	\centering
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_20000_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_20000_multi_res"}}\\
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_30000_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_30000_multi_res"}}
	\caption{Full resolution images (left) and multi-resolution PCA features (right) for two training examples.}
	\label{fig:sub2}
\end{figure}

\begin{figure}[!h]
	\centering
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_40000_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_40000_multi_res"}}\\
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_50000_full_res"}}\quad
	\subfloat[][]{\includegraphics[width=.3\textwidth]{"Example_50000_multi_res"}}
	\caption{Full resolution images (left) and multi-resolution PCA features (right) for two training examples.}
	\label{fig:sub3}
\end{figure}

\noindent
Feature were generated as demonstrated above.  Additionally, I tested taking the 2D FFT of each component image before training the network.  Again, this results in 1016 dimensional  feature vectors for each image.  It should be discussed that while the dimensionality was actually increased (from 784) in this scenario, it was believed that the features would be more discriminative than the raw images alone.  A single network architecture was implemented as described in project 1, consisting of layers (input-256-128-100-10). ReLU activation functions were used in all layers of the network, excluding the output.  Cross-entropy was the implemented cost function and the Adamax optimizer (with and initial learning rate of $\eta=0.01$) implementation in Pytorch was used to update the weights.  Early stopping was applied when the validation error began to increase.  The training set consisted of 60000 samples, the validation, 9000 samples and the hold-out test set, 10000 samples.  The number of samples for each class were evenly distributed in each data split.  Ten models were trained for both feature scenarios and the best model (on validation) was applied to the test set.  Results are shown in the form of confusion matrices in Figure \ref{fig:pcam_confusion_mats} and compared to results obtained from project 1 in Figure \ref{fig:base_confusion_mats}. 


\begin{figure}[h]
	\centering
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"pcam_no_fft_learning_curve"}}\quad
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"pcam_no_fft_confusion_mat"}}\\
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"pcam_fft_learning_curve"}}\quad
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"pcam_fft_confusion_mat"}}
	\caption{Top: Learning curves and confusion matrix from the network trained with Multi-resolution PCA features.  Bottom: Learning curves and confusion matrix from the network trained with frequency-domain Multi-resolution PCA features.}
	\label{fig:pcam_confusion_mats}
\end{figure}

\begin{figure}[h]
	\centering
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"base_confusion_mat"}}\quad
	\subfloat[][]{\includegraphics[width=.4\textwidth]{"pca_100_confusion_mat"}}\\
	\caption{Left: Confusion matrix for the base model trained on raw images. Right: Confusion matrix for model trained with images projected onto the first 100 principal components of the training set.}
	\label{fig:base_confusion_mats}
\end{figure}

\noindent
From the figures, it can be observed that the base model exhibited loss of 0.61, the base PCA retaining 100 dimensions showed 0.34, PCA-M demonstrated 0.38, and the PCA-M with frequency domain features exhibited 0.88 cross-entropy loss.  It is still my belief the PCA-100 model trained for project 1 was ``lucky".  I find it difficult to believe that this model could achieve a lower error than some of the other methods compared.  PCA-M, however, demonstrated statistically equivalent results.  While not shown, the network trained with PCA-M features consistently reached the same performance for all 10 training sessions.  Additionally, while the dimensionality of the features actually increased, it appears that the PCA-M features were actually better descriptors for discrimination than the raw samples. \\

\noindent
Again, PCA does not conserve discriminability through its transformation of data.  Therefore, dimensionality reduction methods which enforce class separability could be investigated as a preprocessing procedure in future work. 

\noindent

 







\end{document}
