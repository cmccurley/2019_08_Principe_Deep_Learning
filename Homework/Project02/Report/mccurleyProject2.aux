\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{McCurley2019PrincipeProject1}
\citation{Xiao2017FashionMNIST}
\citation{Haykin2009NeuralNetworks,Goodfellow2016DeepLearning}
\citation{Lin2011svm,Sanchez2011svm}
\citation{Murphy2012Textbook}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Methodology}{1}{section.2}}
\newlabel{Methodology}{{II}{1}{Methodology}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Data Analysis}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Autoencoder}{1}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Support Vector Machines}{1}{subsection.2.3}}
\citation{Goodfellow2016DeepLearning,Haykin2009NeuralNetworks}
\citation{Xiao2017FashionMNIST}
\citation{Principe2010ITL}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Samples from the Fashion-MNIST dataset. One sample from each class was randomly chosen for visualization. The gray-scale images are size 28x28, each representing an article of clothing.\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:samples}{{1}{2}{Samples from the Fashion-MNIST dataset. One sample from each class was randomly chosen for visualization. The gray-scale images are size 28x28, each representing an article of clothing.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Block diagram of an autoencoder neural network. The layers consecutively reduce dimensionality until the middle (bottleneck) layer. The second half of the network transforms the data back to the size of the input. The desired value of the network is the original image.\relax }}{2}{figure.caption.3}}
\newlabel{fig:autoencoder}{{2}{2}{Block diagram of an autoencoder neural network. The layers consecutively reduce dimensionality until the middle (bottleneck) layer. The second half of the network transforms the data back to the size of the input. The desired value of the network is the original image.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Baseline CNN}{2}{subsection.2.4}}
\citation{Principe2010ITL}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-E}}Information Theoretic Learning}{3}{subsection.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{3}{section.3}}
\newlabel{Results}{{III}{3}{Results}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Reconstructed images of a shoe after passing through an SAE with bottleneck dimensionality 10 (a) and 100 (b). The images' original dimensionality was 784.\relax }}{3}{figure.caption.15}}
\newlabel{fig:ae_reconstruction}{{3}{3}{Reconstructed images of a shoe after passing through an SAE with bottleneck dimensionality 10 (a) and 100 (b). The images' original dimensionality was 784.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}{subfigure.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Autoencoder Reconstruction}{3}{subsection.3.1}}
\newlabel{ae_reconstruction}{{\unhbox \voidb@x \hbox {III-A}}{3}{Autoencoder Reconstruction}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Confusion Matrices}{3}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Comparison of Bottleneck Size}{3}{subsection.3.3}}
\newlabel{classification_accuracy}{{\unhbox \voidb@x \hbox {III-C}}{3}{Comparison of Bottleneck Size}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Confusion matrix for the baseline CNN. The model classified 90\% of the test data correctly.\relax }}{4}{figure.caption.17}}
\newlabel{fig:conf_mat_cnn}{{4}{4}{Confusion matrix for the baseline CNN. The model classified 90\% of the test data correctly.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Confusion matrix for the SVM trained on data passed through an encoder network with bottleneck dimensionality 100. The model classified 86\% of the test data correctly.\relax }}{4}{figure.caption.18}}
\newlabel{fig:conf_mat_svm_100}{{5}{4}{Confusion matrix for the SVM trained on data passed through an encoder network with bottleneck dimensionality 100. The model classified 86\% of the test data correctly.\relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Classification Accuracies for Different Neural Model/ Classification Systems\relax }}{4}{table.caption.16}}
\newlabel{tab:step1comparison}{{I}{4}{Classification Accuracies for Different Neural Model/ Classification Systems\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Comparison of xEnt Kernel Bandwidths}{4}{subsection.3.4}}
\newlabel{bw_comparison}{{\unhbox \voidb@x \hbox {III-D}}{4}{Comparison of xEnt Kernel Bandwidths}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Confusion matrix for the SVM trained on data passed through an encoder network with bottleneck dimensionality 10. The model classified 76\% of the test data correctly.\relax }}{4}{figure.caption.19}}
\newlabel{fig:conf_mat_svm_10}{{6}{4}{Confusion matrix for the SVM trained on data passed through an encoder network with bottleneck dimensionality 10. The model classified 76\% of the test data correctly.\relax }{figure.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Classification Accuracies for Varying xEnt Kernel Bandwidths and Latent Dimensionalities\relax }}{4}{table.caption.20}}
\newlabel{tab:bw_comparison}{{II}{4}{Classification Accuracies for Varying xEnt Kernel Bandwidths and Latent Dimensionalities\relax }{table.caption.20}{}}
\bibdata{Project2}
\bibcite{McCurley2019PrincipeProject1}{1}
\bibcite{Xiao2017FashionMNIST}{2}
\bibcite{Haykin2009NeuralNetworks}{3}
\bibcite{Goodfellow2016DeepLearning}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion matrix for the MLP with a final dimensionality (before output) of $k=100$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }}{5}{figure.caption.21}}
\newlabel{fig:feature_size_100_bw_300}{{7}{5}{Confusion matrix for the MLP with a final dimensionality (before output) of $k=100$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion matrix for the MLP with a final dimensionality (before output) of $k=75$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }}{5}{figure.caption.22}}
\newlabel{fig:feature_size_75_bw_300}{{8}{5}{Confusion matrix for the MLP with a final dimensionality (before output) of $k=75$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Discussion}{5}{section.4}}
\newlabel{Discussion}{{IV}{5}{Discussion}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confusion matrix for the MLP with a final dimensionality (before output) of $k=50$ and a xEnt bandwidth of $\sigma =3$. The model classified 89\% of the test data correctly.\relax }}{5}{figure.caption.23}}
\newlabel{fig:feature_size_50_bw_3}{{9}{5}{Confusion matrix for the MLP with a final dimensionality (before output) of $k=50$ and a xEnt bandwidth of $\sigma =3$. The model classified 89\% of the test data correctly.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Confusion matrix for the MLP with a final dimensionality (before output) of $k=25$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }}{5}{figure.caption.24}}
\newlabel{fig:feature_size_25_bw_300}{{10}{5}{Confusion matrix for the MLP with a final dimensionality (before output) of $k=25$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Results}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Potential Improvements}{5}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusions}{5}{section.5}}
\newlabel{Conclusions}{{V}{5}{Conclusions}{section.5}{}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.27}}
\bibcite{Lin2011svm}{5}
\bibcite{Sanchez2011svm}{6}
\bibcite{Murphy2012Textbook}{7}
\bibcite{Principe2010ITL}{8}
\bibstyle{IEEEtran}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion matrix for the MLP with a final dimensionality (before output) of $k=10$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }}{6}{figure.caption.25}}
\newlabel{fig:feature_size_10_bw_300}{{11}{6}{Confusion matrix for the MLP with a final dimensionality (before output) of $k=10$ and a xEnt bandwidth of $\sigma =300$. The model classified 89\% of the test data correctly.\relax }{figure.caption.25}{}}
